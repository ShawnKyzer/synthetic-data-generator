{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Installing the required dependencies \n",
        "Before we can begin we need to make sure we have all the required dependencies installed in our notebook kernel. You will also want to ensure that you have the configured the correct runtime in the notebook (e.g. GPU or CPU)"
      ],
      "metadata": {
        "id": "Vj5le65hDNRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to avoid future dependency issues we have frozen the versions. \n",
        "# This means you may have to alter these as time goes by and new releases\n",
        "# are available. \n",
        "# From https://github.com/gretelai/gretel-synthetics/blob/master/examples/record_factory.ipynb\n",
        "!pip install gretel-synthetics==0.19.0\n",
        "!pip install pandas-profiling==3.6.2\n",
        "!pip install matplotlib==3.6.3\n",
        "\n",
        "# Restart the runtime for matplot libs updates"
      ],
      "metadata": {
        "id": "9ws1jlBY3O6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - The Setup \n",
        "Now that we have a place to put all our data and persist checkpoints lets start by reading in the data and converting our date column in preparation for the training. "
      ],
      "metadata": {
        "id": "Ji82-W_Vj3Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gretel_synthetics.batch import DataFrameBatch\n",
        "\n",
        "train_df = pd.read_csv(\"https://gretel-public-website.s3-us-west-2.amazonaws.com/tests/synthetics/data/USAdultIncome14K.csv\")"
      ],
      "metadata": {
        "id": "RHmT8tZYki4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 - Training the model\n",
        "We are now ready to configure the model and begin the training using DGAN and batch training of the dataframe. "
      ],
      "metadata": {
        "id": "7w5lofkrnUvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "checkpoint_dir = str(Path.cwd() / \"test-model-2\")\n",
        "\n",
        "config_template = {\n",
        "    \"epochs\": 10000,\n",
        "    \"max_line_len\": 2048,\n",
        "    \"vocab_size\": 200000,\n",
        "    \"field_delimiter\": \",\",\n",
        "    \"overwrite\": True,\n",
        "    \"checkpoint_dir\": checkpoint_dir\n",
        "}\n",
        "\n",
        "batcher = DataFrameBatch(df=train_df, config=config_template, batch_size=5)\n"
      ],
      "metadata": {
        "id": "kHRcQ39fn2vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batcher.create_training_data()\n",
        "batcher.train_all_batches()\n"
      ],
      "metadata": {
        "id": "01US7mSSnoTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigger the batch for all lines generating the same number as in original set for comparison later\n",
        "status = batcher.generate_all_batch_lines(num_lines=train_df.shape[0])\n"
      ],
      "metadata": {
        "id": "OlgxMp3-nzRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_df = batcher.batches_to_df()\n"
      ],
      "metadata": {
        "id": "BRTTpEiOn-zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 - Model Evaluation - How did we do?\n",
        "Now that we have both our initial training set and our generated set lets do a side by side comparision with pandas_profiling. "
      ],
      "metadata": {
        "id": "LWHMOWJrn9n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "# Produce the data profiling report\n",
        "original_report = ProfileReport(train_df, title='Original Data')\n",
        "\n",
        "synthetic_report = ProfileReport(synthetic_df, title='Synthetic Data')\n",
        "\n",
        "comparison_report = original_report.compare(synthetic_report)\n",
        "comparison_report.to_file(\"original_vs_transformed.html\") \n",
        "comparison_report.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "ye4F1Mi4oNXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}